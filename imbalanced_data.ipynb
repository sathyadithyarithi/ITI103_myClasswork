{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sathyadithyarithi/ITI103_myClasswork/blob/main/imbalanced_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DnqURdKXOvF9"
      },
      "source": [
        "# Dealing with Imbalanced Data Set\n",
        "\n",
        "Welcome to the hands-on lab. This is part of the series of exercises to help you acquire skills in different techniques to fine-tune your model.\n",
        "\n",
        "In this lab, you will learn:\n",
        "- how to use over-sampling correctly for imbalanced data set\n",
        "- how to perform resampling using K-folds\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7RwnjO0pOvF-"
      },
      "source": [
        "In this exercise, we will use an imbalanced data set from Lending Club that consists of data for both 'bad' and 'good' loans to illustrate how we can apply oversampling and undersampling techniques to improve our model performance. You will also learn to apply resampling correctly when using cross-validation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLhPfND5OvF-"
      },
      "source": [
        "## Import the libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1155FtcFOvF_"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import urllib.request\n",
        "import shutil\n",
        "import zipfile\n",
        "\n",
        "from sklearn.ensemble import (\n",
        "    RandomForestClassifier,\n",
        "    GradientBoostingClassifier\n",
        ")\n",
        "\n",
        "from sklearn.model_selection import (\n",
        "    train_test_split,\n",
        "    RepeatedStratifiedKFold,\n",
        "    cross_validate\n",
        ")\n",
        "\n",
        "from sklearn.metrics import (\n",
        "    classification_report,\n",
        "    roc_curve,\n",
        "    roc_auc_score,\n",
        "    auc,\n",
        "    precision_recall_curve,\n",
        "    RocCurveDisplay\n",
        ")\n",
        "\n",
        "from imblearn.pipeline import Pipeline\n",
        "\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "from imblearn.ensemble import (\n",
        "    RUSBoostClassifier,\n",
        "    EasyEnsembleClassifier\n",
        ")\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4uzbQmnOvGE"
      },
      "source": [
        "## Get the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKm5pvtTOvGF"
      },
      "source": [
        "url = 'https://nyp-aicourse.s3.ap-southeast-1.amazonaws.com/datasets/lending_club-data.csv.zip'\n",
        "zip_file = \"lending_club-data.csv.zip\"\n",
        "\n",
        "# download the zip file and copy to a file 'lending-club-data.csv.zip'\n",
        "with urllib.request.urlopen(url) as response, open(zip_file, 'wb') as out_file:\n",
        "    shutil.copyfileobj(response, out_file)\n",
        "\n",
        "# unzip the file to a folder 'data'\n",
        "with zipfile.ZipFile(zip_file,\"r\") as zip_ref:\n",
        "    zip_ref.extractall('data')"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUjfEldbOvGI"
      },
      "source": [
        "## Understand the data\n",
        "\n",
        "Here we are trying to find out some information about the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_KUTDi-oOvGJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da57ed0a-5a1d-45c8-a112-223c107af3ea"
      },
      "source": [
        "df = pd.read_csv('data/lending-club-data.csv')"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-42-d319cfea7013>:1: DtypeWarning: Columns (19,47) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv('data/lending-club-data.csv')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1PMtr7wOvGP"
      },
      "source": [
        "Let us just find out about different features and their data types."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_KphBoylOvGQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3508525f-5129-40b6-c890-293ad32ffe73"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 122607 entries, 0 to 122606\n",
            "Data columns (total 68 columns):\n",
            " #   Column                       Non-Null Count   Dtype  \n",
            "---  ------                       --------------   -----  \n",
            " 0   id                           122607 non-null  int64  \n",
            " 1   member_id                    122607 non-null  int64  \n",
            " 2   loan_amnt                    122607 non-null  int64  \n",
            " 3   funded_amnt                  122607 non-null  int64  \n",
            " 4   funded_amnt_inv              122607 non-null  int64  \n",
            " 5   term                         122607 non-null  object \n",
            " 6   int_rate                     122607 non-null  float64\n",
            " 7   installment                  122607 non-null  float64\n",
            " 8   grade                        122607 non-null  object \n",
            " 9   sub_grade                    122607 non-null  object \n",
            " 10  emp_title                    115767 non-null  object \n",
            " 11  emp_length                   118516 non-null  object \n",
            " 12  home_ownership               122607 non-null  object \n",
            " 13  annual_inc                   122603 non-null  float64\n",
            " 14  is_inc_v                     122607 non-null  object \n",
            " 15  issue_d                      122607 non-null  object \n",
            " 16  loan_status                  122607 non-null  object \n",
            " 17  pymnt_plan                   122607 non-null  object \n",
            " 18  url                          122607 non-null  object \n",
            " 19  desc                         60703 non-null   object \n",
            " 20  purpose                      122607 non-null  object \n",
            " 21  title                        122596 non-null  object \n",
            " 22  zip_code                     122607 non-null  object \n",
            " 23  addr_state                   122607 non-null  object \n",
            " 24  dti                          122607 non-null  float64\n",
            " 25  delinq_2yrs                  122578 non-null  float64\n",
            " 26  earliest_cr_line             122578 non-null  object \n",
            " 27  inq_last_6mths               122578 non-null  float64\n",
            " 28  mths_since_last_delinq       50500 non-null   float64\n",
            " 29  mths_since_last_record       12531 non-null   float64\n",
            " 30  open_acc                     122578 non-null  float64\n",
            " 31  pub_rec                      122578 non-null  float64\n",
            " 32  revol_bal                    122607 non-null  int64  \n",
            " 33  revol_util                   122607 non-null  float64\n",
            " 34  total_acc                    122578 non-null  float64\n",
            " 35  initial_list_status          122607 non-null  object \n",
            " 36  out_prncp                    122607 non-null  float64\n",
            " 37  out_prncp_inv                122607 non-null  float64\n",
            " 38  total_pymnt                  122607 non-null  float64\n",
            " 39  total_pymnt_inv              122607 non-null  float64\n",
            " 40  total_rec_prncp              122607 non-null  float64\n",
            " 41  total_rec_int                122607 non-null  float64\n",
            " 42  total_rec_late_fee           122607 non-null  float64\n",
            " 43  recoveries                   122607 non-null  float64\n",
            " 44  collection_recovery_fee      122607 non-null  float64\n",
            " 45  last_pymnt_d                 122271 non-null  object \n",
            " 46  last_pymnt_amnt              122607 non-null  float64\n",
            " 47  next_pymnt_d                 2907 non-null    object \n",
            " 48  last_credit_pull_d           122601 non-null  object \n",
            " 49  collections_12_mths_ex_med   122462 non-null  float64\n",
            " 50  mths_since_last_major_derog  15460 non-null   float64\n",
            " 51  policy_code                  122607 non-null  int64  \n",
            " 52  not_compliant                122607 non-null  int64  \n",
            " 53  status                       122607 non-null  object \n",
            " 54  inactive_loans               122607 non-null  int64  \n",
            " 55  bad_loans                    122607 non-null  int64  \n",
            " 56  emp_length_num               122607 non-null  int64  \n",
            " 57  grade_num                    122607 non-null  int64  \n",
            " 58  sub_grade_num                122607 non-null  float64\n",
            " 59  delinq_2yrs_zero             122578 non-null  float64\n",
            " 60  pub_rec_zero                 122578 non-null  float64\n",
            " 61  collections_12_mths_zero     122462 non-null  float64\n",
            " 62  short_emp                    122607 non-null  int64  \n",
            " 63  payment_inc_ratio            122603 non-null  float64\n",
            " 64  final_d                      122607 non-null  object \n",
            " 65  last_delinq_none             122607 non-null  int64  \n",
            " 66  last_record_none             122607 non-null  int64  \n",
            " 67  last_major_derog_none        122607 non-null  int64  \n",
            "dtypes: float64(29), int64(16), object(23)\n",
            "memory usage: 63.6+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kGorNXkCOvGU"
      },
      "source": [
        "In this exercise, we are trying to predict if a member will default on his loan or not. So we will be using the feature column 'bad_loans' as the label for our classification task. If the value of `bad_loan` is 1, it means it is a default (or bad loan), otherwise, it is 0.  \n",
        "\n",
        "***Exercise:***\n",
        "\n",
        "Find out how many samples in the data set is bad loans and how many are not.\n",
        "\n",
        "Hint: `value_counts()` in [pandas](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.value_counts.html) give you the count of unique values\n",
        "\n",
        "<p>\n",
        "<details><summary>Click here for answer</summary>\n",
        "\n",
        "```python\n",
        "\n",
        "df.bad_loans.value_counts()\n",
        "\n",
        "```\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LxAwMqOLOvGV"
      },
      "source": [
        "### Complete the code below ###\n",
        "\n"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KbTZ3HYROvGZ"
      },
      "source": [
        "Is the data set imbalanced? Clearly we have a lot of more good loans than bad loans (around 4 times more)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-699YfGOvGZ"
      },
      "source": [
        "## Data Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SqFZxW3POvGa"
      },
      "source": [
        "There are quite a lot of features in this data set but we are just going to use a few, just for demonstration purpose (as we are not really interested in actual performance of our model)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GiB1_iyKOvGb"
      },
      "source": [
        "features = ['grade', 'home_ownership','emp_length_num', 'sub_grade','short_emp',\n",
        "            'dti', 'term', 'purpose', 'int_rate', 'last_delinq_none', 'last_major_derog_none',\n",
        "            'revol_util', 'total_rec_late_fee', 'payment_inc_ratio', 'bad_loans']"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QcD4E6QMOvGf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1d017a8-c5c1-4e1a-e6c1-c166a2c2acba"
      },
      "source": [
        "df = df[features]\n",
        "df.info()"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 122607 entries, 0 to 122606\n",
            "Data columns (total 15 columns):\n",
            " #   Column                 Non-Null Count   Dtype  \n",
            "---  ------                 --------------   -----  \n",
            " 0   grade                  122607 non-null  object \n",
            " 1   home_ownership         122607 non-null  object \n",
            " 2   emp_length_num         122607 non-null  int64  \n",
            " 3   sub_grade              122607 non-null  object \n",
            " 4   short_emp              122607 non-null  int64  \n",
            " 5   dti                    122607 non-null  float64\n",
            " 6   term                   122607 non-null  object \n",
            " 7   purpose                122607 non-null  object \n",
            " 8   int_rate               122607 non-null  float64\n",
            " 9   last_delinq_none       122607 non-null  int64  \n",
            " 10  last_major_derog_none  122607 non-null  int64  \n",
            " 11  revol_util             122607 non-null  float64\n",
            " 12  total_rec_late_fee     122607 non-null  float64\n",
            " 13  payment_inc_ratio      122603 non-null  float64\n",
            " 14  bad_loans              122607 non-null  int64  \n",
            "dtypes: float64(5), int64(5), object(5)\n",
            "memory usage: 14.0+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54vsiwgBOvGm"
      },
      "source": [
        "Notice that `payment_inc_ratio` has some null values, and since it is only a small number, just remove the rows that have null values for `payment_inc_ratio`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2LnIJIEOvGn"
      },
      "source": [
        "loans_df = df.dropna()"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZnxh1kf-4N_"
      },
      "source": [
        "We will go ahead and encode our categorical columns."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LtXWlMJuOvGt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19926bd6-4b10-435c-a153-b91323886e9a"
      },
      "source": [
        "loans_encoded = pd.get_dummies(loans_df)\n",
        "loans_encoded.info()"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 122603 entries, 0 to 122606\n",
            "Data columns (total 70 columns):\n",
            " #   Column                      Non-Null Count   Dtype  \n",
            "---  ------                      --------------   -----  \n",
            " 0   emp_length_num              122603 non-null  int64  \n",
            " 1   short_emp                   122603 non-null  int64  \n",
            " 2   dti                         122603 non-null  float64\n",
            " 3   int_rate                    122603 non-null  float64\n",
            " 4   last_delinq_none            122603 non-null  int64  \n",
            " 5   last_major_derog_none       122603 non-null  int64  \n",
            " 6   revol_util                  122603 non-null  float64\n",
            " 7   total_rec_late_fee          122603 non-null  float64\n",
            " 8   payment_inc_ratio           122603 non-null  float64\n",
            " 9   bad_loans                   122603 non-null  int64  \n",
            " 10  grade_A                     122603 non-null  bool   \n",
            " 11  grade_B                     122603 non-null  bool   \n",
            " 12  grade_C                     122603 non-null  bool   \n",
            " 13  grade_D                     122603 non-null  bool   \n",
            " 14  grade_E                     122603 non-null  bool   \n",
            " 15  grade_F                     122603 non-null  bool   \n",
            " 16  grade_G                     122603 non-null  bool   \n",
            " 17  home_ownership_MORTGAGE     122603 non-null  bool   \n",
            " 18  home_ownership_OTHER        122603 non-null  bool   \n",
            " 19  home_ownership_OWN          122603 non-null  bool   \n",
            " 20  home_ownership_RENT         122603 non-null  bool   \n",
            " 21  sub_grade_A1                122603 non-null  bool   \n",
            " 22  sub_grade_A2                122603 non-null  bool   \n",
            " 23  sub_grade_A3                122603 non-null  bool   \n",
            " 24  sub_grade_A4                122603 non-null  bool   \n",
            " 25  sub_grade_A5                122603 non-null  bool   \n",
            " 26  sub_grade_B1                122603 non-null  bool   \n",
            " 27  sub_grade_B2                122603 non-null  bool   \n",
            " 28  sub_grade_B3                122603 non-null  bool   \n",
            " 29  sub_grade_B4                122603 non-null  bool   \n",
            " 30  sub_grade_B5                122603 non-null  bool   \n",
            " 31  sub_grade_C1                122603 non-null  bool   \n",
            " 32  sub_grade_C2                122603 non-null  bool   \n",
            " 33  sub_grade_C3                122603 non-null  bool   \n",
            " 34  sub_grade_C4                122603 non-null  bool   \n",
            " 35  sub_grade_C5                122603 non-null  bool   \n",
            " 36  sub_grade_D1                122603 non-null  bool   \n",
            " 37  sub_grade_D2                122603 non-null  bool   \n",
            " 38  sub_grade_D3                122603 non-null  bool   \n",
            " 39  sub_grade_D4                122603 non-null  bool   \n",
            " 40  sub_grade_D5                122603 non-null  bool   \n",
            " 41  sub_grade_E1                122603 non-null  bool   \n",
            " 42  sub_grade_E2                122603 non-null  bool   \n",
            " 43  sub_grade_E3                122603 non-null  bool   \n",
            " 44  sub_grade_E4                122603 non-null  bool   \n",
            " 45  sub_grade_E5                122603 non-null  bool   \n",
            " 46  sub_grade_F1                122603 non-null  bool   \n",
            " 47  sub_grade_F2                122603 non-null  bool   \n",
            " 48  sub_grade_F3                122603 non-null  bool   \n",
            " 49  sub_grade_F4                122603 non-null  bool   \n",
            " 50  sub_grade_F5                122603 non-null  bool   \n",
            " 51  sub_grade_G1                122603 non-null  bool   \n",
            " 52  sub_grade_G2                122603 non-null  bool   \n",
            " 53  sub_grade_G3                122603 non-null  bool   \n",
            " 54  sub_grade_G4                122603 non-null  bool   \n",
            " 55  sub_grade_G5                122603 non-null  bool   \n",
            " 56  term_ 36 months             122603 non-null  bool   \n",
            " 57  term_ 60 months             122603 non-null  bool   \n",
            " 58  purpose_car                 122603 non-null  bool   \n",
            " 59  purpose_credit_card         122603 non-null  bool   \n",
            " 60  purpose_debt_consolidation  122603 non-null  bool   \n",
            " 61  purpose_home_improvement    122603 non-null  bool   \n",
            " 62  purpose_house               122603 non-null  bool   \n",
            " 63  purpose_major_purchase      122603 non-null  bool   \n",
            " 64  purpose_medical             122603 non-null  bool   \n",
            " 65  purpose_moving              122603 non-null  bool   \n",
            " 66  purpose_other               122603 non-null  bool   \n",
            " 67  purpose_small_business      122603 non-null  bool   \n",
            " 68  purpose_vacation            122603 non-null  bool   \n",
            " 69  purpose_wedding             122603 non-null  bool   \n",
            "dtypes: bool(60), float64(5), int64(5)\n",
            "memory usage: 17.3 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pplOyf8XOvGz"
      },
      "source": [
        "### Split the data set into train and test set\n",
        "\n",
        "***Exercise:***\n",
        "\n",
        "First, separate the features and the label.  \n",
        "\n",
        "Hint: use `df.drop()` and specify `axis=1` to remove a particular column in dataframe.\n",
        "\n",
        "Then, split the data into train set (called `X_train, y_train`) and test set (`X_test, y_test`). Think about the splitting strategy, e.g. do you need to ensure the distribution of good/bad is the same in both train and test set?\n",
        "\n",
        "<p>\n",
        "<details><summary>Click here for answer</summary>\n",
        "    \n",
        "```python\n",
        "\n",
        "X_df = loans_encoded.drop(['bad_loans'], axis=1)\n",
        "y_df = loans_encoded['bad_loans']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_df, y_df,\n",
        "                                                    test_size = .2,\n",
        "                                                    stratify = y_df,\n",
        "                                                    random_state = 42)\n",
        "\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HV7UrEgrOvG0"
      },
      "source": [
        "X_df = loans_encoded.drop(['bad_loans'], axis=1)\n",
        "y_df = loans_encoded['bad_loans']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_df, y_df,\n",
        "                                                    test_size = .2,\n",
        "                                                    stratify = y_df,\n",
        "                                                    random_state = 42)"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CeEr2-jBOvG4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35a95c7e-30d6-4a98-e8a2-6c44596e5ab9"
      },
      "source": [
        "print(y_train.value_counts())"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bad_loans\n",
            "0    79562\n",
            "1    18520\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SmSMM7TE-4OA"
      },
      "source": [
        "## Train a baseline model\n",
        "\n",
        "Now for comparison sake, we will evaluate a baseline model without any resampling.\n",
        "As we are dealing with imbalanced dataset, it is useful for us to look at the roc auc score."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VK2hJam-4OB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d65d539e-99c4-4dc8-bdff-e1c9815db07e"
      },
      "source": [
        "clf = RandomForestClassifier(n_estimators=30, random_state=0)\n",
        "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=1, random_state=0)\n",
        "scores = cross_validate(clf, X_train, y_train, scoring=['roc_auc'], cv=cv, n_jobs=-1)\n",
        "\n",
        "print('ROC_AUC of baseline model = {}'.format(scores['test_roc_auc'].mean()))"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROC_AUC of baseline model = 0.6745330348717996\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T1EwpPy2-4OB"
      },
      "source": [
        "## Oversampling\n",
        "\n",
        "Now we will try the over-sampling techniques to see if we can improve our model performance on the 'bad loan'."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ms9xSxclOvG-"
      },
      "source": [
        "### The ***wrong*** way to oversample ###\n",
        "\n",
        "With the training data created, we can oversample the minority class (the bad_loan = 1). In this exercise, we will use the SMOTE (from the [imblearn](https://imbalanced-learn.readthedocs.io/en/stable/index.html) library) to create synthetic samples of the minority class.\n",
        "\n",
        "After upsampling to a class ratio of 1.0 (i.e. 1 to 1 ratio between positive and negative classes) you should have a balanced dataset. In most cases, there’s often no need to balance the classes totally."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09afPcnaOvG_"
      },
      "source": [
        "# Set sampling_strategy='auto' to oversample only the minority class\n",
        "\n",
        "sm = SMOTE(sampling_strategy='auto',random_state=0)\n",
        "\n",
        "X_upsample, y_upsample = sm.fit_resample(X_train, y_train)"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYewJVUYOvHB"
      },
      "source": [
        "Now let's see the number of samples we have for each class. You will see that now our train set is totally balanced, with equal number of samples for each class.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AzcmiL-YOvHC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f4927ad-6b02-4e2a-e370-0b218de642a8"
      },
      "source": [
        "y_upsample.value_counts()"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "bad_loans\n",
              "0    79562\n",
              "1    79562\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8ewnQ5JOvHI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f232bebb-498a-4426-b890-1320f978b7d4"
      },
      "source": [
        "clf = RandomForestClassifier(n_estimators=30, random_state=0)\n",
        "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=1, random_state=0)\n",
        "scores = cross_validate(clf, X_upsample, y_upsample, scoring=['roc_auc'], cv=cv, n_jobs=-1)\n",
        "\n",
        "print('Cross-validation ROC_AUC score SMOTE-wrong way = {}'.format(scores['test_roc_auc'].mean()))"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-validation ROC_AUC score SMOTE-wrong way = 0.9352371343346733\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IdknGvRgOvHV"
      },
      "source": [
        "Our roc_auc score has improved to 93%. Impressive!  But is this actually representative of how the model will perform? Let's put our model to test."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dyl14DBIOvHL"
      },
      "source": [
        "Now let's train the model using the full up-sampled training set and evaluate on test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5LXxQ5IOvHM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4698c48e-0100-4361-fb32-dcdbb59885c3"
      },
      "source": [
        "clf = RandomForestClassifier(n_estimators=30, random_state=0)\n",
        "clf.fit(X_upsample, y_upsample)\n",
        "\n",
        "y_probas = clf.predict_proba(X_test)[:,1]\n",
        "\n",
        "roc_auc = roc_auc_score(y_test, y_probas)\n",
        "\n",
        "print('Test ROC_AUC with SMOTE-wrong way = {}'.format(roc_auc))"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test ROC_AUC with SMOTE-wrong way = 0.6795601525071902\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "INAtz44QOvHa"
      },
      "source": [
        "You will get around 0.68. That’s disappointing! What has happened?\n",
        "\n",
        "By oversampling before splitting into training and validation datasets, we “leaked” information from the validation set into the training of the model (refer to your lecture for more details)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-fkAmtpOvHb"
      },
      "source": [
        "### The ***right way*** to oversample\n",
        "\n",
        "So, let do it the right way and see what happens. This time round, we will oversample the training set and not the train + validation set. Oversampling is done after we set aside the validation set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfPMduTK-4OD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c04178bf-6ed5-4d71-da4f-4ba8cc2fdde1"
      },
      "source": [
        "sm = SMOTE(sampling_strategy='auto', random_state=0)\n",
        "clf = RandomForestClassifier(n_estimators=30, random_state=0)\n",
        "\n",
        "# declare a pipeline that consists of the oversampler and the classifier\n",
        "steps = [('ovr', sm), ('clf', clf)]\n",
        "pipeline = Pipeline(steps=steps)\n",
        "\n",
        "# the oversampling is only applied to the train folds\n",
        "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=1, random_state=0)\n",
        "scores = cross_validate(pipeline, X_train, y_train, scoring=['roc_auc'], cv=cv, n_jobs=-1)\n",
        "\n",
        "print('average roc_auc = {}'.format(scores['test_roc_auc'].mean()))"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average roc_auc = 0.6678994199969314\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gXzlMLEl-4OD"
      },
      "source": [
        "## Undersampling\n",
        "\n",
        "It does not seems that we have much success with oversampling (it is marginally better than the baseline model). Let us try undersampling to see if we can get a better model.\n",
        "\n",
        "**Exercise:**\n",
        "\n",
        "Complete the code cell below, using RandomUndersampler, resample only the majority class. Cross-validate with RandomForestClassifier like before and compare the result with the oversampling approach. What do you observe about the result?\n",
        "\n",
        "<details><summary>Click here for answer</summary>\n",
        "<br/>\n",
        "    \n",
        "```python\n",
        "\n",
        "undersampler  = RandomUnderSampler(sampling_strategy='auto', random_state=0)\n",
        "clf = RandomForestClassifier(n_estimators=30, random_state=0)\n",
        "\n",
        "# declare a pipeline that consists of the oversampler and the classifier\n",
        "steps = [('under', undersampler), ('clf', clf)]\n",
        "pipeline = Pipeline(steps=steps)\n",
        "\n",
        "# the oversampling is only applied to the train folds\n",
        "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=1, random_state=1)\n",
        "scores = cross_validate(pipeline, X_train, y_train, scoring=['roc_auc'], cv=cv, n_jobs=-1)\n",
        "\n",
        "print('Cross-validation ROC_AUC score Random Undersampling = {}'.format(scores['test_roc_auc'].mean()))\n",
        "    \n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvTaBr3H-4OD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77322ce2-1c84-4be5-966d-7f242cb9e369"
      },
      "source": [
        "undersampler  = RandomUnderSampler(sampling_strategy='auto', random_state=0)\n",
        "clf = RandomForestClassifier(n_estimators=30, random_state=0)\n",
        "\n",
        "# declare a pipeline that consists of the oversampler and the classifier\n",
        "steps = [('under', undersampler), ('clf', clf)]\n",
        "pipeline = Pipeline(steps=steps)\n",
        "\n",
        "# the oversampling is only applied to the train folds\n",
        "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=1, random_state=1)\n",
        "scores = cross_validate(pipeline, X_train, y_train, scoring=['roc_auc'], cv=cv, n_jobs=-1)\n",
        "\n",
        "print('Cross-validation ROC_AUC score Random Undersampling = {}'.format(scores['test_roc_auc'].mean()))\n",
        "\n"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-validation ROC_AUC score Random Undersampling = 0.6811834358533816\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2FqZZfCD-4OE"
      },
      "source": [
        "## Boosting\n",
        "\n",
        "Let us try some boosting algorithm to see if we can achieve better result.\n",
        "\n",
        "**Exercise:**\n",
        "\n",
        "Complete the code cell below, using GradientBoostingClassifier, with default parameters and random_state=0\n",
        "\n",
        "<details><summary>Click here for answer</summary>\n",
        "<br/>\n",
        "    \n",
        "```python\n",
        "clf = GradientBoostingClassifier(random_state=0)\n",
        "\n",
        "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=1, random_state=0)\n",
        "scores = cross_validate(clf, X_train, y_train, scoring=['roc_auc'], cv=cv, n_jobs=-1)\n",
        "print('Cross-validate ROC_AUC with GradientBoosting = {}'.format(scores['test_roc_auc'].mean()))\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ar83qC13-4OE"
      },
      "source": [
        "clf = GradientBoostingClassifier(random_state=0)\n",
        "\n",
        "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=1, random_state=0)\n",
        "scores = cross_validate(clf, X_train, y_train, scoring=['roc_auc'], cv=cv, n_jobs=-1)\n",
        "print('Cross-validate ROC_AUC with GradientBoosting = {}'.format(scores['test_roc_auc'].mean()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ItHRXKgP-4OE"
      },
      "source": [
        "Here we can see that even without any re-sampling, boosting algorithm is able to achieve better result."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k12HQ0b8-4OE"
      },
      "source": [
        "### Complete the code below ###\n",
        "clf = RUSBoostClassifier(n_estimators=30, sampling_strategy='auto', learning_rate=1.0)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}